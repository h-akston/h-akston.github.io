---
permalink: /
title: "Maksim Kulik"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

The Human Language Technology program at the [University of Arizona](https://linguistics.arizona.edu/) has been my home for the last 2 years. I am set to graduate with an MS degree in HLT in May 2025.

I hold a BA degree in Translation Studies and an MA degree in Computational Linguistics. My [most recent work experience](https://h-akston.github.io/portfolio/portfolio-1/) revolved around identifying large language models that support low-resource languages and benchmarking their performance, as well as working on a scoring system to gauge how affected a given low-resource language is by the digital divide. Before that, I worked with text generation for a solar equipment store.

My journey through computational linguistics wasn't planned. It began with translation work that showed me how language carries cultural nuance no dictionary can capture. While translating Deisseroth's "Projections," I became obsessed with how neural networks could accomplish so many language tasks that I struggled to complete manually.

After getting an MA in computational linguistics, I found a job at a solar equipment store. At [A1SolarStore](https://a1solarstore.com/), I pioneered a content generation system that maintained brand voice while scaling production tenfold. The content generation system I built wasn't merely a template-filler. I analyzed hundreds of existing product descriptions to identify the distinctive patterns, metaphors, and technical vocabulary that created the company's unique voice. By implementing a hybrid architecture that combined rule-based principles with neural networks, I created a solution that could generate compelling descriptions for new products while preserving the linguistic identity that customers had come to trust. When A/B tested against human-written content, our system achieved 87% comparable engagement rates while reducing production time from days to minutes.

Two years later, in my final year in the HLT program, I had an opportunity to work for a company that enables organizations to utilize multilingual language models. My work at [XRI Global](https://www.xriglobal.ai/) brought the resource disparity into sharp focus. Testing LLMs across 100+ languages revealed significant performance drops for low-resource languages compared to English, with steeper declines for languages with non-Latin scripts. This inequity in linguistic resources manifests in everything from poor sentiment analysis to inaccurate translation. My LLM benchmarking work at XRI Global revealed how dramatically performance drops for languages like my native Russian compared to English â€” a gap I'm determined to help close.

The future of language technology isn't just about processing words but understanding meaningful human communication. My work experience combines applied linguistics with machine learning to create adaptive systems that respond to individual language patterns and contextual nuances.

